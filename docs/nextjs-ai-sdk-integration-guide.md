# Next.js + AI SDK é›†æˆæŒ‡å—ï¼šæ„å»ºæµå¼AIèŠå¤©ç³»ç»Ÿ

æœ¬æŒ‡å—åŸºäºå®é™…é¡¹ç›®å¼€å‘ç»éªŒï¼Œè¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨Next.jsåº”ç”¨ä¸­é›†æˆAI SDKæ¥æ„å»ºæµå¼AIèŠå¤©ç³»ç»Ÿï¼Œæ”¯æŒå¤šAIæ¨¡å‹é€‰æ‹©ã€‚

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®è®¾ç½®ä¸ä¾èµ–å®‰è£…](#1-é¡¹ç›®è®¾ç½®ä¸ä¾èµ–å®‰è£…)
2. [ç¯å¢ƒé…ç½®](#2-ç¯å¢ƒé…ç½®)
3. [æ•°æ®åº“è®¾è®¡](#3-æ•°æ®åº“è®¾è®¡)
4. [TypeScriptç±»å‹å®šä¹‰](#4-typescriptç±»å‹å®šä¹‰)
5. [åç«¯APIå®ç°](#5-åç«¯apiå®ç°)
6. [å‰ç«¯UIç»„ä»¶](#6-å‰ç«¯uiç»„ä»¶)
7. [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#7-å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
8. [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#8-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
9. [æœ€ä½³å®è·µ](#9-æœ€ä½³å®è·µ)

## 1. é¡¹ç›®è®¾ç½®ä¸ä¾èµ–å®‰è£…

### æ ¸å¿ƒä¾èµ–

```bash
# AI SDK v5.0 - æ ¸å¿ƒåŒ…
pnpm add ai @ai-sdk/openai @ai-sdk/react

# OpenAIå®¢æˆ·ç«¯ï¼ˆå¦‚æœä½¿ç”¨OpenAIå…¼å®¹APIï¼‰
pnpm add openai

# React Markdownæ”¯æŒ
pnpm add react-markdown

# æ•°æ®åº“å’Œè®¤è¯ï¼ˆä½¿ç”¨Supabaseï¼‰
pnpm add @supabase/supabase-js

# UIç»„ä»¶åº“
pnpm add @radix-ui/react-select @radix-ui/react-scroll-area
pnpm add class-variance-authority clsx tailwind-merge
pnpm add sonner # Toasté€šçŸ¥

# å¼€å‘ä¾èµ–
pnpm add -D @types/react @types/node
```

### ç‰ˆæœ¬å…¼å®¹æ€§é‡è¦æç¤º

âš ï¸ **å…³é”®æ³¨æ„äº‹é¡¹**ï¼š
- AI SDK v5.0 ä¸ v4.0 APIæœ‰é‡å¤§å˜åŒ–
- ç¡®ä¿æ‰€æœ‰AIç›¸å…³åŒ…ç‰ˆæœ¬ä¸€è‡´
- å»ºè®®å›ºå®šç‰ˆæœ¬é¿å…è‡ªåŠ¨å‡çº§å¯¼è‡´çš„é—®é¢˜

```json
{
  "dependencies": {
    "ai": "5.0.0",
    "@ai-sdk/openai": "2.0.0", 
    "@ai-sdk/react": "2.0.0",
    "openai": "5.11.0",
    "react-markdown": "10.1.0"
  }
}
```

## 2. ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡è®¾ç½®

åˆ›å»º `.env.local` æ–‡ä»¶ï¼š

```bash
# OpenAI APIé…ç½®
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1  # æˆ–è‡ªå®šä¹‰APIç«¯ç‚¹

# Supabaseé…ç½®
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
```

### Supabaseå®¢æˆ·ç«¯é…ç½®

```typescript
// lib/supabase/client.ts
import { createBrowserClient } from '@supabase/ssr'

export const createClient = () => 
  createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )

// lib/supabase/server.ts  
import { createServerClient } from '@supabase/ssr'
import { cookies } from 'next/headers'

export const createClient = () => {
  const cookieStore = cookies()
  
  return createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        getAll() {
          return cookieStore.getAll()
        },
        setAll(cookiesToSet) {
          try {
            cookiesToSet.forEach(({ name, value, options }) =>
              cookieStore.set(name, value, options)
            )
          } catch {
            // å¿½ç•¥åœ¨æœåŠ¡ç«¯è®¾ç½®cookieæ—¶çš„é”™è¯¯
          }
        },
      },
    }
  )
}
```

## 3. æ•°æ®åº“è®¾è®¡

### Supabaseæ•°æ®åº“è¿ç§»

```sql
-- åˆ›å»ºèŠå¤©è¡¨
CREATE TABLE chats (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  model TEXT NOT NULL DEFAULT 'gpt-3.5-turbo',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- åˆ›å»ºæ¶ˆæ¯è¡¨
CREATE TABLE messages (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  chat_id UUID REFERENCES chats(id) ON DELETE CASCADE,
  role TEXT NOT NULL CHECK (role IN ('user', 'assistant')),
  content TEXT NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- åˆ›å»ºupdated_atè§¦å‘å™¨
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = TIMEZONE('utc'::text, NOW());
  RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_chats_updated_at BEFORE UPDATE ON chats
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- åˆ›å»ºRLSç­–ç•¥
ALTER TABLE chats ENABLE ROW LEVEL SECURITY;
ALTER TABLE messages ENABLE ROW LEVEL SECURITY;

-- èŠå¤©RLSç­–ç•¥
CREATE POLICY "Users can view own chats" ON chats
  FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own chats" ON chats
  FOR INSERT WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own chats" ON chats
  FOR UPDATE USING (auth.uid() = user_id);

CREATE POLICY "Users can delete own chats" ON chats
  FOR DELETE USING (auth.uid() = user_id);

-- æ¶ˆæ¯RLSç­–ç•¥
CREATE POLICY "Users can view messages from own chats" ON messages
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM chats 
      WHERE chats.id = messages.chat_id 
      AND chats.user_id = auth.uid()
    )
  );

CREATE POLICY "Users can insert messages to own chats" ON messages
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM chats 
      WHERE chats.id = messages.chat_id 
      AND chats.user_id = auth.uid()
    )
  );
```

## 4. TypeScriptç±»å‹å®šä¹‰

### å®Œæ•´ç±»å‹å®šä¹‰

```typescript
// types/chats.ts
export interface Chat {
  id: string
  user_id: string
  title: string
  model: string
  created_at: string
  updated_at: string
}

export interface Message {
  id: string
  chat_id: string
  role: 'user' | 'assistant'
  content: string
  created_at: string
}

export interface CreateChatRequest {
  title?: string
  model?: string
}

export interface CreateMessageRequest {
  chat_id: string
  role: 'user' | 'assistant'
  content: string
}

export interface ChatWithLastMessage extends Chat {
  lastMessage?: Message
  lastMessageTime?: string
}

// AIæ¨¡å‹é…ç½®
export const AI_MODELS = {
  'gpt-3.5-turbo': {
    name: 'GPT-3.5 Turbo',
    description: 'å¿«é€Ÿã€é«˜æ•ˆçš„é€šç”¨AIæ¨¡å‹',
    provider: 'openai'
  },
  'qwen3-235b-a22b-2507:free': {
    name: 'Qwen3-235B (å…è´¹)',
    description: 'é˜¿é‡Œå·´å·´å¤§è¯­è¨€æ¨¡å‹å…è´¹ç‰ˆ',
    provider: 'custom'
  },
  'glm-4.5-flash': {
    name: 'GLM-4.5 Flash',
    description: 'æ™ºè°±AIå¿«é€Ÿå“åº”æ¨¡å‹',
    provider: 'custom'
  },
  'ernie-4.5-vl-28b-a3b': {
    name: 'ERNIE-4.5-VL-28B',
    description: 'ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹å¤šæ¨¡æ€ç‰ˆæœ¬',
    provider: 'custom'
  }
} as const

export type AIModelKey = keyof typeof AI_MODELS

// AI SDK v5.0 æ¶ˆæ¯æ ¼å¼
export interface UIMessage {
  id: string
  role: 'user' | 'assistant'
  parts: Array<{
    type: 'text'
    text: string
  }>
}
```

## 5. åç«¯APIå®ç°

### èŠå¤©APIè·¯ç”± (app/api/chat/route.ts)

```typescript
import { createOpenAI } from '@ai-sdk/openai'
import { streamText, convertToModelMessages } from 'ai'
import { createClient } from '@/lib/supabase/server'

export async function POST(req: Request) {
  try {
    const { messages, chatId } = await req.json()
    
    // éªŒè¯ç”¨æˆ·è®¤è¯
    const supabase = createClient()
    const { data: { user }, error: userError } = await supabase.auth.getUser()
    
    if (userError || !user) {
      console.error('Auth error:', userError)
      return new Response('Unauthorized', { status: 401 })
    }

    // éªŒè¯chatIdï¼ˆå¦‚æœæä¾›ï¼‰å¹¶è·å–æ¨¡å‹ä¿¡æ¯
    let selectedModel = 'gpt-3.5-turbo' // é»˜è®¤æ¨¡å‹
    if (chatId) {
      const { data: chat, error: chatError } = await supabase
        .from('chats')
        .select('user_id, model')
        .eq('id', chatId)
        .single()

      if (chatError || !chat || chat.user_id !== user.id) {
        console.error('Chat access error:', { chatError, chat, userId: user.id })
        return new Response('Chat not found or unauthorized', { status: 404 })
      }
      selectedModel = chat.model || 'gpt-3.5-turbo'
    }

    // éªŒè¯ç¯å¢ƒå˜é‡
    if (!process.env.OPENAI_API_KEY || !process.env.OPENAI_BASE_URL) {
      console.error('Missing OpenAI configuration')
      return new Response('Server configuration error', { status: 500 })
    }

    // åˆ›å»ºOpenAIå®ä¾‹
    const openai = createOpenAI({
      baseURL: process.env.OPENAI_BASE_URL,
      apiKey: process.env.OPENAI_API_KEY,
    })

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const modelMessages = convertToModelMessages(messages)

    // å¤„ç†è‡ªå®šä¹‰æ¨¡å‹
    let modelToUse = selectedModel
    if (!['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo'].includes(selectedModel)) {
      console.log('Using custom model:', selectedModel)
    }

    // åˆ›å»ºæµå¼å“åº”
    const result = await streamText({
      model: openai.chat(modelToUse),
      messages: modelMessages,
      async onFinish({ text }) {
        // ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
        if (chatId && text) {
          try {
            // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            const userMessage = messages[messages.length - 1]
            if (userMessage && userMessage.role === 'user') {
              const userContent = userMessage.parts?.find(part => part.type === 'text')?.text || ''
              
              await supabase.from('messages').insert({
                chat_id: chatId,
                role: 'user',
                content: userContent,
              })
            }

            // ä¿å­˜AIå›å¤
            await supabase.from('messages').insert({
              chat_id: chatId,
              role: 'assistant',
              content: text,
            })

            console.log('Messages saved successfully')
          } catch (dbError) {
            console.error('Database save error:', dbError)
          }
        }
      },
    })

    return result.toTextStreamResponse()
  } catch (error) {
    console.error('Chat API error:', error)
    return new Response('Internal server error', { status: 500 })
  }
}
```

## 6. å‰ç«¯UIç»„ä»¶

### ä¸»èŠå¤©é¡µé¢ç»„ä»¶

```typescript
// app/chat/[id]/page.tsx
'use client'

import { useEffect, useState, useRef } from 'react'
import { useChat } from '@ai-sdk/react'
import { getChats, getChatMessages, createChat } from '@/lib/actions/chat-actions'
import { Message as MessageType, ChatWithLastMessage } from '@/types/chats'
import { toast } from 'sonner'
import ReactMarkdown from 'react-markdown'

interface ChatPageProps {
  params: Promise<{ id: string }>
}

export default function ChatPage({ params }: ChatPageProps) {
  const [chatId, setChatId] = useState<string>('')
  const [chats, setChats] = useState<ChatWithLastMessage[]>([])
  const [initialMessages, setInitialMessages] = useState<MessageType[]>([])
  const [isLoading, setIsLoading] = useState(true)
  const [input, setInput] = useState('')
  const [isAiLoading, setIsAiLoading] = useState(false)
  const scrollAreaRef = useRef<HTMLDivElement>(null)

  // ä½¿ç”¨AI SDK 5.0çš„useChat hook
  const {
    messages,
    setMessages,
  } = useChat({
    onError: (error) => {
      console.error('Chat error:', error)
      toast.error('å‘é€æ¶ˆæ¯å¤±è´¥ï¼Œè¯·é‡è¯•')
      setIsAiLoading(false)
    },
    onFinish: () => {
      loadChats()
      setIsAiLoading(false)
    },
  })

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTop = scrollAreaRef.current.scrollHeight
    }
  }, [messages])

  // æäº¤è¡¨å•å¤„ç†
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault()
    if (!input.trim() || !chatId || isAiLoading) return
    
    const message = input.trim()
    setInput('')
    setIsAiLoading(true)
    
    try {
      // è°ƒç”¨èŠå¤©API
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: [
            ...messages,
            {
              id: Date.now().toString(),
              role: 'user',
              parts: [{ type: 'text', text: message }]
            }
          ],
          chatId: chatId,
        }),
      })
      
      if (!response.ok) {
        throw new Error('Failed to send message')
      }

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ç•Œé¢
      const userMessage = {
        id: Date.now().toString(),
        role: 'user' as const,
        parts: [{ type: 'text', text: message } as const]
      }

      const newMessages = [...messages, userMessage]
      setMessages(newMessages)

      // å¤„ç†æµå¼å“åº”
      const reader = response.body?.getReader()
      if (!reader) {
        throw new Error('No response body reader')
      }

      const decoder = new TextDecoder()
      let aiResponse = ''
      const aiMessageId = (Date.now() + 1).toString()

      try {
        while (true) {
          const { done, value } = await reader.read()
          if (done) break
          
          const chunk = decoder.decode(value, { stream: true })
          aiResponse += chunk
          
          // æ›´æ–°AIæ¶ˆæ¯
          const aiMessage = {
            id: aiMessageId,
            role: 'assistant' as const,
            parts: [{ type: 'text', text: aiResponse } as const]
          }
          
          setMessages([...newMessages, aiMessage])
        }
      } catch (streamError) {
        console.error('Stream processing error:', streamError)
        throw new Error(`Stream error: ${streamError}`)
      }
      
    } catch (error) {
      console.error('Failed to send message:', error)
      toast.error('å‘é€æ¶ˆæ¯å¤±è´¥ï¼Œè¯·é‡è¯•')
    } finally {
      setIsAiLoading(false)
    }
  }

  return (
    <div className="flex flex-col h-full">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div ref={scrollAreaRef} className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <div key={message.id} className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}>
            <div className={`max-w-[80%] rounded-lg p-3 ${
              message.role === 'user' 
                ? 'bg-primary text-primary-foreground' 
                : 'bg-muted'
            }`}>
              {message.role === 'assistant' ? (
                <ReactMarkdown className="prose prose-sm dark:prose-invert">
                  {message.parts[0]?.text || ''}
                </ReactMarkdown>
              ) : (
                <p>{message.parts[0]?.text || ''}</p>
              )}
            </div>
          </div>
        ))}
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="border-t bg-background p-4">
        <form onSubmit={handleSubmit} className="flex gap-2 items-end max-w-4xl mx-auto">
          <div className="flex-1 relative">
            <textarea
              value={input}
              onChange={(e) => setInput(e.target.value)}
              placeholder="è¾“å…¥ä½ çš„æ¶ˆæ¯..."
              disabled={isAiLoading}
              className="w-full resize-none rounded-lg border border-input bg-background px-3 py-2 text-sm"
              rows={1}
              onKeyDown={(e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                  e.preventDefault()
                  if (input.trim() && !isAiLoading) {
                    handleSubmit(e)
                  }
                }
              }}
            />
          </div>
          
          <button
            type="submit"
            disabled={!input.trim() || isAiLoading}
            className="px-4 py-2 bg-primary text-primary-foreground rounded-lg disabled:opacity-50"
          >
            {isAiLoading ? 'å‘é€ä¸­...' : 'å‘é€'}
          </button>
        </form>
      </div>
    </div>
  )
}
```

## 7. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜1ï¼šAI SDKç‰ˆæœ¬å…¼å®¹æ€§

**ç—‡çŠ¶**ï¼š
```
Module not found: Can't resolve 'ai/react'
Property 'input' does not exist on type 'UseChatHelpers'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®ä¿ä½¿ç”¨AI SDK v5.0
- ä½¿ç”¨ `@ai-sdk/react` è€Œä¸æ˜¯ `ai/react`
- æ£€æŸ¥æ‰€æœ‰ç›¸å…³åŒ…ç‰ˆæœ¬ä¸€è‡´

```bash
pnpm remove ai @ai-sdk/openai @ai-sdk/react
pnpm add ai@5.0.0 @ai-sdk/openai@2.0.0 @ai-sdk/react@2.0.0
```

### é—®é¢˜2ï¼šæ¶ˆæ¯æ ¼å¼è½¬æ¢é”™è¯¯

**ç—‡çŠ¶**ï¼š
```
Invalid prompt: The messages must be a ModelMessage[]
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ `convertToModelMessages` è½¬æ¢UIæ¶ˆæ¯æ ¼å¼

```typescript
import { convertToModelMessages } from 'ai'

// åœ¨APIè·¯ç”±ä¸­
const modelMessages = convertToModelMessages(messages)
```

### é—®é¢˜3ï¼šè‡ªå®šä¹‰APIç«¯ç‚¹é…ç½®

**ç—‡çŠ¶**ï¼š
```
Incorrect API key provided
model not found or incompatibility
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
æ­£ç¡®é…ç½®OpenAIæä¾›è€…

```typescript
import { createOpenAI } from '@ai-sdk/openai'

const openai = createOpenAI({
  baseURL: process.env.OPENAI_BASE_URL, // è‡ªå®šä¹‰ç«¯ç‚¹
  apiKey: process.env.OPENAI_API_KEY,
})

// ä½¿ç”¨chatç«¯ç‚¹è€Œä¸æ˜¯completion
const result = await streamText({
  model: openai.chat(selectedModel),
  messages: modelMessages,
})
```

### é—®é¢˜4ï¼šæµå¼å“åº”å¤„ç†

**ç—‡çŠ¶**ï¼š
- AIå›å¤ä¸æ˜¾ç¤º
- æµå¼æ•°æ®è§£æé”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
ç®€åŒ–æµå¼å“åº”å¤„ç†

```typescript
// å®¢æˆ·ç«¯æµå¼å¤„ç†
const reader = response.body?.getReader()
const decoder = new TextDecoder()
let aiResponse = ''

while (true) {
  const { done, value } = await reader.read()
  if (done) break
  
  // ç›´æ¥è§£ç æ–‡æœ¬å†…å®¹
  const chunk = decoder.decode(value, { stream: true })
  aiResponse += chunk
  
  // æ›´æ–°UI
  setMessages([...newMessages, {
    id: aiMessageId,
    role: 'assistant',
    parts: [{ type: 'text', text: aiResponse }]
  }])
}
```

### é—®é¢˜5ï¼šæ•°æ®åº“è¿æ¥å’ŒRLS

**ç—‡çŠ¶**ï¼š
```
column chats.model does not exist
Chat not found or unauthorized
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®ä¿æ•°æ®åº“è¿ç§»æ­£ç¡®æ‰§è¡Œ
- éªŒè¯RLSç­–ç•¥é…ç½®
- æ£€æŸ¥ç”¨æˆ·è®¤è¯çŠ¶æ€

```sql
-- æ‰‹åŠ¨æ·»åŠ ç¼ºå¤±å­—æ®µ
ALTER TABLE chats ADD COLUMN model TEXT NOT NULL DEFAULT 'gpt-3.5-turbo';

-- éªŒè¯RLSç­–ç•¥
SELECT * FROM chats WHERE auth.uid() = user_id;
```

## 8. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 8.1 æ¶ˆæ¯åˆ†é¡µåŠ è½½

```typescript
// å®ç°æ¶ˆæ¯åˆ†é¡µ
const MESSAGES_PER_PAGE = 50

export async function getChatMessages(
  chatId: string, 
  page: number = 0
): Promise<Message[]> {
  const { data: messages, error } = await supabase
    .from('messages')
    .select('*')
    .eq('chat_id', chatId)
    .order('created_at', { ascending: false })
    .range(page * MESSAGES_PER_PAGE, (page + 1) * MESSAGES_PER_PAGE - 1)

  return messages?.reverse() || []
}
```

### 8.2 å®æ—¶æ›´æ–°ä¼˜åŒ–

```typescript
// ä½¿ç”¨Supabaseå®æ—¶è®¢é˜…
useEffect(() => {
  if (!chatId) return

  const subscription = supabase
    .channel(`messages:${chatId}`)
    .on('postgres_changes', 
      { 
        event: 'INSERT', 
        schema: 'public', 
        table: 'messages',
        filter: `chat_id=eq.${chatId}`
      }, 
      (payload) => {
        const newMessage = payload.new as Message
        // æ›´æ–°æ¶ˆæ¯åˆ—è¡¨
      }
    )
    .subscribe()

  return () => {
    subscription.unsubscribe()
  }
}, [chatId])
```

## 9. æœ€ä½³å®è·µ

### 9.1 é”™è¯¯å¤„ç†ç­–ç•¥

```typescript
// åˆ†å±‚é”™è¯¯å¤„ç†
export class ChatError extends Error {
  constructor(
    message: string,
    public code: string,
    public statusCode: number = 500
  ) {
    super(message)
    this.name = 'ChatError'
  }
}

// APIè·¯ç”±é”™è¯¯å¤„ç†
export async function POST(req: Request) {
  try {
    // ... ä¸šåŠ¡é€»è¾‘
  } catch (error) {
    if (error instanceof ChatError) {
      return new Response(error.message, { status: error.statusCode })
    }
    
    console.error('Unexpected error:', error)
    return new Response('Internal server error', { status: 500 })
  }
}
```

### 9.2 ç±»å‹å®‰å…¨

```typescript
// ä½¿ç”¨ä¸¥æ ¼çš„TypeScripté…ç½®
{
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true,
    "noImplicitReturns": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true
  }
}

// è¿è¡Œæ—¶ç±»å‹éªŒè¯
import { z } from 'zod'

const MessageSchema = z.object({
  role: z.enum(['user', 'assistant']),
  content: z.string().min(1),
  chatId: z.string().uuid(),
})

export async function POST(req: Request) {
  const body = await req.json()
  const validatedData = MessageSchema.parse(body)
  // ... å¤„ç†éªŒè¯åçš„æ•°æ®
}
```

### 9.3 å®‰å…¨è€ƒè™‘

```typescript
// è¾“å…¥éªŒè¯å’Œæ¸…ç†
import DOMPurify from 'isomorphic-dompurify'

const sanitizeContent = (content: string): string => {
  return DOMPurify.sanitize(content, {
    ALLOWED_TAGS: ['p', 'br', 'strong', 'em', 'code', 'pre'],
    ALLOWED_ATTR: []
  })
}

// é€Ÿç‡é™åˆ¶
import { Ratelimit } from '@upstash/ratelimit'

const ratelimit = new Ratelimit({
  redis: redis,
  limiter: Ratelimit.slidingWindow(10, '1 m'), // æ¯åˆ†é’Ÿ10æ¬¡è¯·æ±‚
})

export async function POST(req: Request) {
  const identifier = getClientIdentifier(req)
  const { success } = await ratelimit.limit(identifier)
  
  if (!success) {
    return new Response('Too many requests', { status: 429 })
  }
  
  // ... å¤„ç†è¯·æ±‚
}
```

## æ€»ç»“

è¿™ä¸ªæŒ‡å—æ¶µç›–äº†ä»é›¶å¼€å§‹æ„å»ºNext.js + AI SDKæµå¼èŠå¤©ç³»ç»Ÿçš„å®Œæ•´æµç¨‹ã€‚å…³é”®è¦ç‚¹ï¼š

1. **ç‰ˆæœ¬ç®¡ç†**ï¼šç¡®ä¿AI SDKç›¸å…³åŒ…ç‰ˆæœ¬ä¸€è‡´
2. **é”™è¯¯å¤„ç†**ï¼šå®ç°åˆ†å±‚é”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
3. **æ•°æ®å®‰å…¨**ï¼šä½¿ç”¨RLSå’ŒServer Actionsä¿æŠ¤æ•°æ®
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šå®ç°æµå¼å“åº”ã€æ¶ˆæ¯åˆ†é¡µå’Œè™šæ‹ŸåŒ–
5. **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨TypeScriptå’Œè¿è¡Œæ—¶éªŒè¯
6. **ç”¨æˆ·ä½“éªŒ**ï¼šæä¾›å®æ—¶åé¦ˆå’Œä¼˜é›…çš„åŠ è½½çŠ¶æ€

é€šè¿‡éµå¾ªè¿™äº›æœ€ä½³å®è·µï¼Œä½ å¯ä»¥æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€å®‰å…¨å¯é çš„AIèŠå¤©ç³»ç»Ÿã€‚ 